---
layout: post
title: OS虚拟化
date: 2019-07-15 15:08:42
categories: 
- [Operate System]
tags:  [虚拟化]
---

# 操作系统导论

## 操作系统

1. 程序运行的过程: 执行指令
   - 内存中fetch（取址）-- decode（解码） -- excuse（执行）具体的操作
   - 冯诺依曼计算机模型
   
2. 操作系统作用：
   - 程序运行需要内存调度, 设备交互;
   - OS 作用: 确保系统易于使用且高效运行；
   
3. OS 如何实现程序的高效运行：
   - **虚拟化**: 将物理资源(CPU, 内存, 磁盘)转换为更通用, 更强大的虚拟形式;
   - 标准库API: 用户与OS交互的接口, 告诉操作系统执行哪些功能;
   - **资源管理器**: OS充当的角色, 合理高效的分配资源
   
4. 时分共享
   
   + 让每一个进程感觉到**独占**了CPU和很大的地址空间;
   
5. **虚拟化**
   
   + 虚拟化的抽象模型:
     + 假设有一个桃子(物理桃子), 但是有很多人想占有它
     + 虚拟化: 将一个物理桃子, 变成多个虚拟的桃子, 造成一种假象.
   
   - 虚拟化CPU :  机制 + 策略
     - 硬件资源 + OS : 虚拟化实现多个CPU, 可执行多个进程;
     - 实现方式: 采用**多级反馈队列**的调度方式, 在**同级优先度**的情况下采用**轮转**策略, 和**上下文切换**的机制, 完成进程的调度
   - 虚拟化内存
     - OS 在单一的物理内存上为多个进程构建一个私有的, 很大的**地址空间**抽象;
       - 用户程序生成的每个地址(能够看见的)都是虚拟地址;
     - 实现方式: 通过最少最近使用**LRU缓存替换**策略, 使得总体TLB**未命中**的比例最小;采用**分页**的机制, 快速的从虚拟地址中得到物理地址;
   - **进程是虚拟化的CPU, 地址空间是虚拟化的内存;**
   

## 虚拟化CPU

1. 机制的理解: 如何(how) 提供答案?
   
   + 时分分享机制: 上下文切换
   
2. 策略的理解: 那个(which) 问题?
   
   + 轮转: RR时间片进行上下文的切换
   
3. **调度策略存在为了优化机制的?**

   + 虚拟化CPU的机制

     + SJF / STCF : 周转时间;
     + RR 时间片轮转: 响应时间
     + MLFQ : 优化周转时间和响应时间的指标

   + 虚拟化内存的机制 

     + base/bound : 内部碎片

       ```
       physical adress = virtual adress + base	// 地址转换
       ```

     + 分段: 外部碎片

       ```
       physical adress = base[segment] + offset
       ```

     + 分割和合并: 减少内外碎片;

     + 分页 + TLB: 实现快速的虚拟地址转换

       ```
       phyadress = PFN 组合 offset; (位连接)
       ```
       
     
   + 除了物理内存之外, 还有硬盘;

### 进程

1. 进程的定义:

   - 从机器状态去理解: 进程是运行中的程序; 
     - 内存: 程序运行中读取和写入的数据就在内存中;
     - 寄存器: 指令明确读取和更新寄存器;
   - OS提供的基本**抽象**

3. 程序是如何转化为进程的

   - 通过OS进行控制:
     - 将代码和静态数据, 加载到内存
     - 为程序运行时的栈分配内存;
     - 为程序的堆(heap)分配内存; 堆: 动态内存申请;
   
4. 进程存在的状态?

   - 进程运行在: CPU + I/O交互

   - 基本的三种状态: 运行 + 就绪 + 阻塞

     {% asset_img process.png %}

   - other: 初始化状态 + 结束状态

   - PCB 进程控制块: 记录进程的信息的数据结构, 进程列表

### 进程API -- 用户如何调用进程

1. 进程API接口
   - 创建 , 销毁, 等待, 其他控制, 状态;
2. fork() 
   - 创建新进程: 父进程返回新的pid, 子进程返回0;
3. wait()
   - 父进程等待子进程运行完时, 才运行自己;
4. exec()
   - 让子进程执行和父进程不同的功能;
5. fork() - exec() 设计的API
   - 给shell 在fork之后, exec 之前执行其他代码的功能
   - 重定向的实现: **>** 关闭了标准输出, 输出到文件中;

### 机制 受限直接执行

1. 问题一: 如何解释受限?
   + 进程必须能够执行I/O和其他的一些受限操作, 但又不能让进程完全控制OS.
2. 如何实现受限执行
   + 提供两种模式: 用户模式和内核模式
   + 内核模式: 系统调用时, 进程执行前必须执行陷阱(trap) 指令和陷阱处理程序
3. **问题二: 如何实现进程间的切换**?
   + a) 首先: OS 获取CPU的控制权
     + 协作方式: 当进程在进行系统调用是, 将CPU的控制权转交给OS
     + 非协作方式: 重启 / 时钟中断
   + b) 保存和恢复上下文文切换
     + OS 为正在执行的进程**保存**一些寄存器的值;
     + 并为即将执行的进程**恢复**一些寄存器的值;
   + 内核模式下, OS控制进程执行陷阱和陷阱处理程序, 时钟中断以及操作系统和硬件在程序间切换, 谨慎的保存和恢复上下文的状态.

### 策略 进程调度

1. 概念: 工作负载的概念?

   + 进程运行过程中: 
   + 既有运行时间短, 响应时间快, 频繁放弃CPU的交互型I/O工作;
   + 也存在需要很多CPU时间, 响应时间并不是很重要的长时间计算型工作.

2. 调度指标一 : **周转时间**

   ```
   T(周转时间) = T(完成时间) - T(到达时间) // 一般使用平局周转时间,也就是完成所有进程时间
   ```

   + 策略一: **SJF**  shortest job first
     + 使用最短任务优先策略的前提: 所有工作同一时间到达;
     + 非抢占式
   + 策略二: **STCF** shortest time-to-completion first
     + 抢占式的: 最短完成时间优先的一种调度策略;
   + 两种策略的问题:
     + 只考虑周转时间; 
     + 而且需要**提前**知道工作完成的时间;(不可能实现的)

3. 调度指标二 : **响应时间**

   ```
   T(响应时间) = T(首次运行时间) - T(到达时间) 	// 使用的是平均响应时间
   ```

   + 策略: **轮转 RR ** round- robin
     + 衡量一种时间片RR(time slice)的大小;
     + 让每一个进程交替运行RR时间片的长度, 直到所有工作完成
   + 轮转策略问题
     + RR时间片很小的情况下, 上下文的切换成本将会影响整体性能;
     + 只关注响应时间;

4. 调度策略:  **重叠**

   + 通过使用重叠, 更好的利用资源;
   + 重叠的实现:
     + 在进程A I/O申请时, 切换进程B;
     + 然后当进程A I/O释放时, 由B进程切换到A;

### 调度: 多级反馈队列

1. MLFQ需要解决的问题 (multi-level feedback queue) 

   + 优化周转时间: 基于STCF策略
   + 优化响应时间: 基于轮转策略

2. 使用MLFQ调度规则的前提条件?

   + MLFQ拥有许多独立的队列, 每个队列有不同的**优先级**
   + 任何时刻, 一个工作只能存在与一个队列中;

3. MLFQ 如何实现调度?

   + 通过观察工作运行状态调整其对应的优先级;
     + 对于不断放弃CPU等待键盘输入的工作, 保持其高优先级
     + 对于长时间占用CPU的工作, 不断降低其优先级;
   + 相同优先级采用的策略: **轮转**

4. MLFQ最重要的一个工作就是设置优先级?

   {% asset_img mlfq.jpg %}

### 调度: 比例份额

1. 比例份额调度算法:
   + 确保每个工作获得一定比例的CPU时间, 而不是优化周转时间和响应时间
2. 比例份额存在问题?
   + 比例份额如何分配?
   + 随机性: 不能很好的适应 I/O的操作;

### 调度 :多处理器调度

1. 多处理器和单处理器(CPU)区别?

   + 硬件缓存cache的使用

     + 缓存的共享: 通过**总线**的方式实现一致性

     {% asset_img mcpu.jpg %}

   + 多处理器之间共享数据的方式

     + 同步: 通过**加锁**的将多个函数封装为原子操作;

2. 多处理器和单处理器(CPU)切换的问题?

   + C应用程序的问题
     + 重写C应用程序, 大部分只用到一个CPU;
     + 多线程并行执行, 将工作分散到多个CPU上

## 虚拟化内存

1. 为什么要虚拟化内存?
   + OS让每一个程序员觉得, 它是有用一个很大的连续地址存储空间, 用来存放其代码和数据;
   + 隔离和保护: 不希望错误的程序读写或者覆盖其他程序的内存;
2. 如何实现虚拟化?
   
   +  硬件 + OS 将这些虚拟地址映射为内存中实际的物理地址, 从而读取内存中的数据;
   
   + 机制: 地址转换 
     + **动态重定向和分段**: 基于基址/界限寄存器进行转换地址
     + **内存空间分页** : 基于TLB地址缓存, 根据VA中的VPN快速得到PA;
   + 策略: 
     + 使用最少最近使用LRU缓存替换策略, 使得总体未命中的比例最小;

### 地址空间

1. 地址空间的概念?
   + OS 对物理内存的一个抽象.
2. 如何实现有效的时分共享方法?
   + 在进行上下文切换的时候, 将进程的状态信息保存在地址空间上;
   + 这样能保证进程读写的效率;
3. **虚拟内存**
   + 虚拟内存: 是OS操作系统的一个重要子系统;
   + 虚拟内存的四个特点
     + 透明: 为程序提供一个巨大的, 稀疏的, 私有的地址空间的**假象**, 其中保存了程序的所有指令和数据;
     + 效率: 通过每一个虚拟内存的索引, 将虚拟地址转换为物理地址, 物理内存根据物理地址获取所需信息;
     + 保护: 确保程序之间互不影响;
     + 灵活性: 程序以任何方式访问自己的内存;

### 内存操作API 

1. 内存分为哪几种类型?

   + 栈内存: 它的申请和释放由编译器隐式管理, 自动内存;

     ```
     int x;	// 栈内存的申请, 用于存取临时的变量和值;
     ```

   + 堆(heap)内存 : 它的申请是程序员**显示**调用**库函数**(不是系统调用);

     + 程序员不主动释放, 即使进程关闭, 堆内存也会一直存在, 只不过会出现**内存泄露**问题

     ```
     int *x = (int *)malloc(sizeof(int))	// 栈和堆的分配在同一行
     int *x  : 申请一个整形指针栈空间;
      malloc(sizeof(int)): 在堆上请求整数的空间, 成功返回一个整数地址, 并**存储在栈**上供程序调用;
     ```
     
     + 字符串的动态申请
     
     ```
     char *string = (char *)malloc(strlen(string) + 1); 字符串一定要加1, 存在'\0'
     ```

3. 为什么**堆内存**要进行释放free(), 栈内存不进行释放?

   + 系统中存在两级内存管理

     + 第一级: 操作系统执行的内存管理, 会在进程关闭时进行回收;
     + 第二级: 在每个进程中进行堆内管理;

   + 内存泄漏: 

     + 长时间运行的服务器, 当内存不够使用时, 就会发生内存泄露问题, 导致系统崩溃;

       ```
       valgrind: 查找程序中内存泄露的问题
       ```

   + 反复释放内存

     + 重复释放内存: 会造成错误double free

4. 其他内存申请的接口

   + mmap() 调用操作系统获取内存
   + calloc(): 内存分配库
   + realloc():创建一个新的更大的内存, 并将旧区域复制到新区域中;

### 机制 : 地址转换 ( 实现方式:  单基址/界限)

2. 如何实现**地址转换**?

   + 硬件: 程序运行时, 硬件对每次**内存的访问**进行处理, 将VA(vitrual)转换为PA(physical); 将应用程序**重定向**到物理内存, 读取相应的数据;
   + OS: 在关键点进行**介入**, 设置好硬件, 管理内存; 记录占用/空闲的内存位置;
   
3. 动态**(基于硬件)**的重定位 

   + CPU包含两个寄存器

     + 基址寄存器(base): 将虚拟地址转化为物理地址

       ```
       physical adress = virtual adress + base	// 地址转换
       ```

     + 界限寄存器(bound): 确保地址在进程地址范围内;

       ```
       初期的内存分配: 每个进程分配固定大小的bound内存空间
       ```

   + **内存管理单元(MMU)**: 负责地址转换的部分

     + 也就是 **基址/界限**的地址转换;

   + **硬件产生异常**

     + 当用户尝试非法访问内存时, CPU能够产生异常

4. 动态的重定位(**OS的作用**)

   + OS正确设置硬件后, 只有在**进程产生异常**时才介入, 其余时间任凭进程运行在CPU上;

   {% asset_img os_Dynamic_relocation.jpg %}

5. 基址/界限 的地址转换方法存在的问题?

   + 内部碎片: 地址空间的分配是固定大小的槽块;
   + 解决方式: 分段的概念;

### 机制: 分段(多基址/界限)

1. 泛化的基址/界限

   + 地址空间中保存了三个段: 代码段, 堆段, 栈段
   + **每一个段**:  包含一对base/bound; ( 动态重定位是三个段: 只包含一对 )
   
2. 段寄存器的概念？

   + 段寄存器: 每个段中含有一对基址/界限 寄存器
   + **段错误**: 虚拟地址转化为内存地址时, 越过了界限值;

3. **分段后: 如何进行地址转换**?

   + 虚拟地址的二进制形式;

     ```
     0-2bit: 00- code -- 01 -- heap
     (n-2)bit: offset
     ```

   + **地址转换**

     ```
     physical adress = base[segment] + offset
     ```

   + 地址转换 -- stack

     + 栈: 反向增长的;
     + 确保反向偏移量的绝对值小于段的界限;

4. 分段有哪些优势?

   + 减少动态重定位中造成的内部碎片, 更好的支持稀疏地址空间;
   + 代码共享: 增加**段**保护位, 这个段可以被映射到多个虚拟空间, 实现共享;

5. 分段造成的问题?

   + 由于段的稀疏分布, 造成地址空间中含有多个小的已分配的内存空间;
   + **外部碎片**: 无法找到一个连续大的空闲的地址空间;

### 空闲空间管理MMU

+ 这里不思考虚拟化, 思考空闲的内存管理MMU.

1. 针对外部碎片: 如何减少外部碎片的产生, 更好的维护空间内存?
   + 内部碎片: 地址空间分给了进程后, 一部分未使用;
   + 外部碎片: 地址空间没有分配给进程, 但是被分配的段空间隔成非连续的空间;
2. 底层机制:  
   + 分割与合并: 
     + 对空闲内存的基本操作, 满足用户的空间需求;
   + 追踪已分配的内存空间
     + 在用户malloc申请堆内存时: 分配一个头部(记录了空间大小) + 用户空间;
     + 在用户free()时, 根据这个头部指针能快速定位: 释放了头部 + 用户空间;
   + 嵌入空闲列表
     + 通过 头部 + 剩余空间数目：描述堆中空闲的内存块；
3. 基本策略（在满足用户需求下，减少外部碎片）
   + 需要额外的查找开销：最优/最差匹配　
   + 首次匹配：找到一个足够大的就返回给用户；
   + 下次匹配：维护一个指针，指向上次查找位置；
4. 空闲空间管理的模型: **伙伴系统**
   + 通过 2^N 进行分割合并;
   + 其分配的空间大小: 按照一分为二的原则进行;

### 机制: 分页

1. **分段**: 将一个进程的地址空间, 分割成长度不一的逻辑段(代码, 堆, 栈);

   + 代码 , 堆, 栈: 各自映射为一个虚拟内存;

2. **分页**: 将一个内存地址空间, 分割成固定大小的单元, 这个单元称为页;

   + 每一个页 --> 称为页帧; 物理页帧PFN (physical page frame number)
   + 每一个页帧 --> 包含为一个虚拟内存
   
3. **分页后: 如何进行地址转换?**

   + 页表:  page table

     + 记录虚拟页放在物理内存中的位置;
     + 是每个进程**单独的**数据结构;
     + **保存在物理内存**中的: 需要访问内存才能实现地址转换;

   + 虚拟地址包含两个部分

     + 虚拟页面号VPN: virtual page number
     
     ```
      计算VPN的大小: 总的地址空间(总的bit) / 每个页的大小
     ```
     
     + 页内偏移量offset: 
     
     ```
      offset(bit) = 总的(bit) - VPN(bit) 
     ```
   
   + **地址转换**
   
     ```
     通过VPN找到物理内存中的PFN;
     phyadress = PFN 组合 offset; (位连接)
     ```

### 分页优化: 快速地址转换(TLB)

1. 对内存地址分页后, 存在哪些问题?

   + **页表**记录单元页的地址映射信息, 保存在物理内存中的;
   + **问题一:**   VA->PA  , 需要对内存中的页表进行访问, 增加时间开销;

2. 解决的方法

   + 增加硬件: 地址转换缓存TLB (地址转换旁路缓冲存储器)translation-lookaside buffer;

     + TLB: 记录的是 -- 已经经过VA --> PA 映射的记录; 

       ```
    VPN | PFN | 其他位
       ```
     
   + 分页 + TLB 模式

3. 分页 + TLB 模式 : **如何实现地址转换**

   + VA :　先从VA中得到VPN 虚拟页号;
   + **TLB命中** 查找含有 VPN记录 :  PFN 组合 offset --> PA --> 访问内存;
   + **TLB未命中** 查找TLB的记录没有VPN: 
     + RISC 精简指令集, 软件管理TLB处理:???
     + a) 硬件 : 抛出异常
     + b) OS : 提升为内核模式, 跳转到陷阱处理程序, 完成页表的映射转换, 更新TLB, 从陷阱返回;
     + c) 硬件: 再次查找, 此时TLB命中;

4. **上下文切换时** -- TLB的处理

   + 问题: 
     + TLB 包含的物理地址映射只对当前进程有效(除非标识共享), 对其他进程无效( vaild 有效位标识);
   + 解决方式 : 增加地址空间标识ASID
     + TLB就可以记录不同进程的地址转换;
     + 在上下文切换时, 根据ASID进行查找
   + TLB 替换策略
   
5. TLB 包含的内容

   {% asset_img TLB.jpg %}

### 页表优化: 多级页表

1. **问题二** : 分页过多, 造成页表记录太大的问题?

2. 解决的问题: 如何降低页表的大小?

3. 方法一: 分段 + 分页

   + 虚拟地址解析:

   ```
   seg(2bit) + VPN(页的个数) + offset()
   ```

   + 缺点: 还是存在分段,  因此空间分配不是那么灵活, 会造成外部碎片

4. 方法二: 多级页表

   + 实现方式

     + 将页表分配成页大小的单元;
     + 整页的页表无效, 就不分配页表;
     + 页目录结构PDE(page directory entries)包含
       + 有效位valid bit : 记录整页页表是否有效
       + 页帧号PFN

     {% asset_img PDE.jpg %}

   + 虚拟地址解析三部分

     ```
     (VPN = )[页目录PDE + 页表索引] + offset
     ```

   + 多级页表的缺陷

     + 多级页表可以尽可能提供较小的表
     + 但是当TLB未命中时, 需要从内存**加载两次**, 才能获取正确的地址转换信息;
       + 一次用于页目录;(PDE)
       + 一次用于页表索引(PTE) 

### 超越物理内存 : 机制

1. 上面的地址空间, 我们一直假设: 能全部放入物理内存?

   + 内存层级: 
     + 用到的地址空间: 保存在物理内存中;
     + 未用到的地址空间: 保存在硬盘上;
   + 虚拟内存的实现 : 物理内存 + 硬盘

2. 交换空间定义:

   + 在硬盘上开辟出一块空间用于**物理页PFN** 的移入和移出;

3. **两个概念**

   + TLB:  地址转换缓存 (地址转换旁路缓冲存储器)

     + 保存的是: 已经经过VA --> PA 映射的记录; 

       ```
       VPN | PFN | 其他位
       ```

   + PTE : 页表, 存储于物理内存 / 硬盘上的 列表

     + 保存的是: 虚拟页VPN 和 物理页PFN 的对应关系;

4. **物理页放在交换空间, 如何处理TLB未命中的情况?**

   + 存在位 valild bit
     + 1 : 存在与物理内存中的PTE页表中;
     + 0:  不存在物理内存中, 触发**页错误**;
   + 页错误的处理
     + OS 进入内核模式: 发送请求给 交换空间的PTE页表
     + 如果PFN 存在于PTE页表中: 将其物理页交换到内存中, 并将地址转换记录更新到TLB中; 然后硬件重新执行
     + 如果PFN 不存在于PTE: OS kill杀死进程;


### 超越物理内存 : 策略

1. 最优策略的目的是什么?
   + 使得总体**未命中**的比例最小;
2. TLB缓存未命中的三种情况
   + 强制性: 缓存一开始为空, 第一次引用;
   + 容量: TLB空间不足, 需要踢出一些记录, 更换新的记录
   + 冲突: 出现在硬件中;
3. 策略
   + 先入先出FIFO
   + 随机踢出
   + 最少最近使用LRU(Least-Recently used)
4. 如何实现LRU策略
   + 增加一个使用位 use bit
   + 时钟算法: 当找到一个use bit 为0 的记录, 就将其踢出替换;
   + 注意:
     + 脏页: 通过使用一个dirty bit 记录;
     + 脏页: 是不进行替换的, 它改变的值要写入磁盘;
5. 频繁分页到硬盘, 成本太高; 所以过度分页最好的办法 : 购买更多的内存;