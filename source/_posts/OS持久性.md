---
layout: post
title: OS持久性
date: 2019-07-24 15:29:42
categories: [Operate System]
tags: 持久性
---

# 持久性

1. 抽象模型
   + 采用什么样的方式, 让数据(**桃子**)保存的时间长久;
2. 持久性完成工作:
   + 数据的有效存储;
3. 硬件中断的实现过程: 
   - 设备准备好自身的工作 --->  发出硬件中断 ---> CPU 执行OS 中预先定义的中断服务例程ISR(interrupt server routine) / 中断处理程序(interrupt handler) ---> 返回唤醒等待的I/O进程继续执行.
4. 调度策略
   + 调度策略的形成: 侧重于不同的影响因素而造成的;
   + 因此: 不用去记忆调度策略, 反而应该知道影响因素; 

## I/O 设备 -- 数据交互

### 问题一: OS 如何与I/O设备进行交互的? 

1. 将设备的硬件接口纳入到OS;

   + **封装**设备驱动程序(OS中的一部分软件): 完成底层操作;

   {% asset_img file_system.jpg %}

   + 驱动程序充满了整个内核;

### 标准硬件

1. 原型系统架构的分层模型:

   + 物理布局和造价成本决定的分层;

   {% asset_img system.jpg %}

2. 标准硬件

   + 硬件接口: 寄存器 ( { status ,  data ,  command } +  register )
     + 操作系统控制设备工作的接口
   + 内部结构: CPU + Memory + 芯片
     + 完成具体接口的工作;

### 标准协议 

+ OS 对硬件接口的**statue register** 进行**polling**
+ OS下发数据到**data register**
  + CPU参与数据移动: 称之为PIO(programmer I/O)
+ OS 下发**command**, 进行命令的执行

1. **问题一** : 如何减polling中cpu的开销?
   + **硬件中断实现:**
   + 优势: 中断允许计算与I/O重叠; (CPU可以执行其他进程)
   + **中断改进**
     + polling + interrupt: 先轮询一段时间, 时间超过某一个阈值, 选择进行中断; ( 防止有些CPU/IO 交换很快, 此时使用中断造成资源浪费 )
     + 合并: 抛出中断时, 等待一段时间;
2. **问题二**: 如何实现高效的数据传输?
   +  增加硬件设备:  DMA (direct memory access) 
   + DMA作用: 协调内存和设备间的数据交互, 无需CPU介入;
3. **问题三**: OS的交互指令是什么?
   + 方法一: I/O指令 -- 特权指令
     + OS是唯一能与硬件设备直接交互的实体; 
   + 方法二: 内存映射I/O
     + 硬件将设备寄存器作为内存地址提供;

## 硬件 -- 数据存储设备

+ 设备: 长久的保存数据, 用户更关心的是数据
+ 内存: 断电后内容会丢失;

### 磁盘驱动器  (I/O操作太慢)

1. 硬件接口:

   + 大量的**扇区块**( 512 byte ), 每个块可以进行读取和写入;

2. 几何扇区如何进行数据存储

   + 磁性: 对磁盘引入磁性, 进行数据永久保存
   + 磁道: 一个同心圆;
   + 磁头: 用于在磁道上读取或者写入数据的;
   + 数据读取过程: 磁道 **逆时针**旋转, 到了磁头下面, 进行数据操作

3. 磁盘的特性

   + 单磁道: 旋转延时;
   + 多磁道: 寻道时间
   + 外磁道比内磁道有更多的存储空间;
   + 缓存cache: 磁道缓存区

   {% asset_img disk.jpg %}

4. **问题一:** 数据是如何与磁盘进行交互的?

   + 磁头通过**寻道**移动到不同的磁道上, 磁盘的逆时针旋转, 将不同的**扇区块**移动到磁头下面, 从而完成数据交互;

5. **问题二** : 数据交互的时间?

   ```
   T(I/O) = T(寻道time) + T(旋转) + T(数据移动)
   ```

6. **问题三**: 磁盘调度策略 -- 降低数据交互时间

   + 根据不同的影响因素, 有不同的策略;

   + **最短寻道时间优先**
   + **最短定位时间优先**

### RAID (廉价冗余磁盘阵列)

1. RAID (Redundant Array of Inexpensive Disks)

   + 将大量的独立磁盘扩充为更大, 更可靠的单一实体;
   + **透明性:** 使用RAID替换磁盘, 不用考虑更换软件驱动;

2. RAID 的特性

   + 性能: 加快I/O读取时间;
   + 容量: 扩充磁盘
   + 可靠性: **冗余**进行数据的物理备份

3. 硬件接口和内部

   + 硬件接口: 线性的数组块, 每个块都可以通过文件系统进行读取和写入;
   + 内部: 专业的计算机, 有一个CPU + Memory + 磁盘

4. **问题一**: 如何设计RAID?

   + 方法: 根据对RAID的特性的不同偏重, 设计不同的RAID;

   

   | RAID的类型          | 特性                                                         |
   | ------------------- | ------------------------------------------------------------ |
   | RAID 0 级: 条带化   | 无冗余, 全部用来存储,  容量大                                |
   | RAID 1 级: 镜像     | 对每个逻辑块, 保留两个物理副本; 只有一半的容量, 但是更可靠了 |
   | RAID 4 级: 奇偶校验 | 容量是(N-1); 需要一个块保存奇偶校验位                        |

## 文件和目录 

+ 文件和目录的用途:  便于用户识别以及查找
+ 文件系统: 通过对磁盘的管理, 便于文件和目录的存储

1. **OS虚拟化**另一个模块:

   + 进程: 虚拟化的CPU;地址空间: 虚拟化的物理内存;
   + 持久存储的虚拟化
     + 文件和目录: 保持数据掉电不丢失;
   
2. **文件的概念**搭建

   + **数据的存储**: 是一个线性数组, 每个字节都可以读取或者写入;
   + **元数据 **: 包含了文件其余的信息,(比如-- inode number (低级名字))
   + 文件系统: 将数据永久的保存在磁盘上;

3. **目录的概念**搭建

   + 目录: 对应我们常说的文件夹;
   + 文件的存储位置: 存放文件的空间;
   + **包含** : 包含一个列表, 列表的信息( 用户可读名字, inode元数据 )
   + **结构:** 根目录只是一个 -- " / ";  子目录通过**分隔符** 隔开

   {% asset_img dirtree.jpg %}

### 文件的相关操作

1. 文件相关API接口

   + open(); write(); read(); close();
   + 下面介绍的系统调用, 将上面的接口进行封装;

2. **工具**使用

   + **strace**追踪系统调用

   ```
   $ strace cat file;  // strace追踪cat命令对文件的操作过程;
   $ dd if=file;			// dd 实用追踪
   ```

   + **stat/fstat**文件信息的查看

   ```
   $	stat	file;	// 查看文件的相关信息
   $	ls -a/-al 			; // 列出目录下文件
   ```

3. 文件的**创建** -- 文件描述符

   ```
   fd = open();  // fd--文件描述符
   ```

   + **文件描述符**: 指向文件的指针, 用于访问读写;

   + 第一次创建文件: fd==3

     ```
     运行的进程已经打开了三个文件
     fd=0 / 1 / 2 --> 	stdin; stdout; stderr;
     ```

   + **文件的创建**做了两件事

     + inode: 创建一个数据结构inode, 跟踪文件的全部信息;
     + link: 将用户可读名链接到该文件, 并将该链接放入目录中;

4. 文件的**读写**

   + 顺序的读写

     ```
     $ strace	echo	hello	>	file;	// echo将hello重定向到文件file中;
     $	strace	cat	file;							// 获取file中的文件内容;
     ```

   + 通过偏移量的读取

     ```
     $	off_t lseek(int fd, off_t offset, int whence);	
     ```

   + 强制写入磁盘, 而非buffer

     ```
     $	fsync(int fd);		// 强制写入磁盘
     ```

5. 文件的其余操作

   ```
   $	strace	mv	file	foo;	// 文件的重命名, rename;
   $	strace	rm	*;					// 文件删除, 删除当前目录下文件
   $	strace	rm -rf	*;				// 递归删除目录下的: **所有文件和目录**
   ```

6. **文件的链接** 

   + 硬链接

     + 创建链接后, unlink()其中一个用户可读名file, 对另外的没有影响;
     + 缺陷:  (1)不能创建目录的硬链接(成环); (2)只能在当前磁盘分区创建

     ```
     $	ln	file	file2;	// link在创建链接的目录中创建了另外一个名称, 该文件不以任何方式复制
     $	ls	-i	file	file2;		// 查看两个文件的inode
     $	stat	file2;
     ```

   + 符号链接 symbolic link (软链接)

     + 创建软连接后, unlink() file, 会使得file2指向不存在的路径

     ```
     $	ln -s file file2;	// 将链接指向文件的**路径名 file**作为链接文件的数据, 链接到一个名为file的数据;	
     $	ls	-al	file	file2;	// 查看
     $	stat	file	;		查看
     ```

### 目录的相关操作

1. 目录的相关API接口

   ```
   $	opendir();	readdir();	closedir();
   ```

2. 目录的**创建**

   ```
   $	strace	mkdir	foo	;	// 创建目录(文件夹) 空目录foo			
   ```

3. **读取**:  创建的目录中不为空, 包含两个条目

   ```
   $	ls	-a/-al	foo		// 目录的读取, 包含两个条目;  " . "
   ./		: 引用自身的条目
   ../		: 引用其父目录的条目;
   ```

4. 目录的删除

   ```
   $	strace	rmdir	foo;	// 只有当目录foo为空(只包含./ ../ 两个条目), 删除才能成功
   ```



## 文件系统

### VSFS(Very Simple File System)

1. 文件系统的创建和挂载

   + 将众多底层文件系统创建成完整的目录树;
   + **mkfs**: 文件系统的创建工具
   + **mount** 文件挂在工具;

   ```
   $ mount	-t	/dev/sda1	/home/user;
   ```


#### 问题一: 文件系统如何实现存储?

+ 磁盘上用那些数据结构存储文件系统的**数据和元数据**;

1. 磁盘的存储:

   + 磁盘分块:	一个block的大小是4KB
   + 数据:  user Data + inode(256 byte)
   + 空间空间管理: Ibit (inode bit) + Dbit(inode bit)
   + Superblock: 包含文件的特定信息, data和inode有多少个块使用;
     + mount 挂在文件系统时, OS将superblock加载到文件树中;

   {% asset_img vsfs.jpg %}

2. iNode的数据结构:

   + iNode的作用: 能有效存储数据块信息,并可以提供有效的访问; (指向数据块的位置)
   + 4k大小的inode : 由256byte构成的一个iNode block;
   + 数据结构: 可以使用指针, 链表, 树 .... 

3. 目录组织

   + 目录只包含一个二元组列表( 条目名称, inode号 )
   + 每个目录还有两个额外的条目

   {% asset_img inode.jpg %}

#### 问题二: 文件系统是如何实现磁盘数据的读写?

+ 假设此时的文件系统已经**挂载**, superblock已经包含在内存中;

1. 访问路径: /foo/bar
   + 文件系统 --> 读取i-number --> 访问inode --> 递归遍历路径名, 找到文件;
2. 写入磁盘
   + 首先: 分配一个磁盘间块(allocate)
   + 然后: 5次的I/O读取
     + 读data bit(查看可分配) , 写 data bit (跟新位图)
     + 读 inode bit,  写 inode bit
     + 写入data
3. 缓存和缓冲 -- 缩短时间
   + 系统内存(DRAM)
   + 在第一次读取的时候, 保存访问路径和条目, 后面访问就很快;

### 快速文件系统FFS( fast file system)

1. VSFS 与 FFS 之间 -- 对磁盘的处理方式:
   + VSFS 文件系统
     + 磁盘: 将磁盘分块4KB
     + 内部碎片的问题: 将磁盘当做**随机存储**的内存;
   + FFS 文件系统
     + 磁盘: 将磁盘划分为分组, 称为柱面组(块组)
     + 处理方式: 相关的东西放在一起, 将**磁盘当做磁盘**;
     + 优点: 减少寻道时间;
2. 后续文件系统的宗旨: 将**磁盘当做磁盘**
   + Linux 中的文件系统 : ext2 和ext3;

### FSCK 和 日志

1. 文件系统的数据结构必须**持久**的**保存**在数据设备上(SSD);

2. 工作负载: 以某种形式更新磁盘的文件系统;

3. **问题:** 当设备遇到断电和崩溃时, 文件系统和磁盘实际存储记录不一致的问题?

   + 组合为六种情况: inode元数据,  bit位图, data数据 

   {% asset_img question.jpg %}

4. **处理方式一**: Fsck (file system checker )

   +  Fsck 是一个工具
   + 抽象模型: 搜索整个房子找钥匙;
   + 方式 : 遍历文件系统的三部分,  inode元数据,  bit位图, data数据 部分
   + 缺点: 很慢

5. **处理方式二**: 日志(预写日志)

   + 处理方式: 在更新磁盘时, 加入一个小注记(预写), 并组织成日志

     ```
     类似于: git commit -m "注记"
     ```

   + 日志: 要写入文件系统中的, journalblock日志超级块;

   + 修复: 文件系统利用日志记录的内容, 堆其进行修复

   + 用的最多的日志: **有序元数据日志**

### 日志结构的文件系统

+ LFS log-structured file system: 另外的一种文件系统

1. LFS磁盘更新的方式:
   + 将**所有要更新**的data + inode 缓存在内存段中; 当段满的时候, 它会一次长时间的**顺序写入**到磁盘未使用的空间;
   + LFS核心: **顺序写入 + 永不覆盖**(旧空间的回收)
2. **问题一**: 每次都会产生新的 inode, 那么如何进行查找呢?
   + inode 映射: 
     + 建立 inode number 和 inode(元数据) 间接层, 
     + 每次通过 inode number , 生成最新版本的**磁盘地址**;
   + inode 映射存储在哪里呢?
     + LFS 在磁盘上**只有这样一个固定**的位置, 检查点区域CR(checkpoint region);
     + CR: 指向最新的inode映射片段
3. **问题二:** LSR会产生很多垃圾空间, 如何对这些空间进行回收?
   + 数据库中的方法**影子分页** : 永不覆盖, 旧空间的回收;
   + 策略: 旧空间回收的策略?

### 数据完整性和保护

+ 保护 和 花费(时间和空间) 总是成正比关系的;

1. **问题** : 磁盘并不完美, 可能会发生故障, 如何才能保证有效的数据?
   + 磁盘故障模型: 
     + 故障 -- 停止 模型 :  构建RAID磁盘
     + 故障 -- 部分 模型;
   + 完整性: 通过对数据的校验完成;
2. **故障一** : 潜在扇区错误LSE(latent sector error)
   + 故障原因: 磁盘内部**数据位**出现错误;
   + **检测方式**: 磁盘内纠错码ECC(error correcting code)
     + 确定块中的磁盘位是够良好;
   + **解决方法**: 冗余机制
3. **故障二**: 磁盘块出现讹误(corrupt)
   + 故障原因: 磁盘块出现错误, ECC检测不出来, 用户得到的却是其他的数据块
   + **检测方法**:  校验和
4. **校验和函数的计算方法:**
   + 异或 XOR : 通过对所有数据的二进制形式求异或  
     + 缺陷:	相同位置的两位发生变化(0/1), 检测不出来;
   + 加法: 每个数据块执行二进制补码加法, 忽略溢出;
     + 缺陷: 数据被移位, 也检测不出来;
   + [循环冗余校验CRC: ( Cyclic Redundancy Check )](https://blog.51cto.com/winda/1063951)
     + 计算方式: 数据块 % 校验位
     + 缺陷: 除法计算太花时间

### [CRC计算方法](https://blog.51cto.com/winda/1063951)

+ **抽象模型**: 

  + 发送端和接收端: 选定的某个特定数( CRC多项式二进制形式)做**模2除法**
  + 发送端: 要在原始的数据帧**后面附加一个数**（计算得到的CRC校验码），生成一个新帧发送给接收端。
  + 接收端: 接收到的新帧 % 特定数, 如果余数为0, 则数据正确;

+ **模2除法**

  + **宗旨**: 既不向上借位, 也不产生进位

  ```
  模2加法运算为：1+1=0，0+1=1，0+0=0，无进位，也无借位
  模2减法运算为：1-1=0，0-1=1，1-0=1，0-0=0，也无进位，无借位
  ```

  + **本质**: 模二运算, 相当于是**异或**

  + {% asset_img mod2.png %}

+ **CRC多项式** 的选取

  ```
  假设: G（X） = X4 + X3 + 1; 		// 二进制形式 11001
  多项式 G(X) = x^k + ... + 1			// 总共 ( k + 1 )位
  ```

+ **发送端**: 计算得到该帧的CRC校验码( FCS帧校验序列）

  ```
  假设数据帧 : 10110011 --->  计算时后面补** k** 个0; 得到k位的CRC码进行替换
  CRC多项式二进制: 11001(k=4)
  ```

  + {% asset_img CRC.png %}

  + 把上步计算得到的CRC校验**0100**替换原始帧10110011**0000**后面的四个“0”，得到新帧10110011**0100**。再把这个新帧发送到接收端。

+ **接收端 : **

  ```
  新的数据帧: 101100110100
  CRC多项式: （X） = X4 + X3 + 1; ( k = 4)
  进行模2除法: 101100110100 % 11001
  ```

  + 余数为0 , 数据正确;

## 分布式系统 ( 由多个机器构成 )

1. 分布式系统的模型抽象
   + 如何让**不同的人, 在不同的时刻**都能吃到桃子, 而且桃子还能保持**新鲜**;
   + 如何保证数据有效, 而且是最新的;
2. 分布式系统解决的问题:
   + client -- > server 通信问题, 通信并不可靠
   + **主要问题:**  通信中如何处理故障(failure);

### 分布式系统的核心  -- 通信

1. 通信并不可靠, 丢包是网络基本的现象:

   + 消息传递层: 传输层, 使用UDP/IP 和 TCP/IP

2. 抽象通信:

   + 分布式共享内存DSM(distributed shared memory)
   + 作用: 使得**不同机器**上运行的**进程共享**一个大的虚拟地址空间;
   + 故障: 指向一个不存在的地址空间

3. **远程过程调用RPC**(Remote Procedure call)

   + 作用: 	使在远程机器上执行代码的过程, 像调用本地函数一样简单;

   + 包括两部分:  存根生成器 和 运行时库

   + **存根生成器**

     + 作用: 消除将函数参数和结果打包成消息的一些痛处;
     + 实现效果:  相同的接口, 自动生成不同的代码.
     + **问题一: ** 复杂的参数, 如何发送一个复杂的数据结构
     + **问题二: ** 并发性服务器组织方式, 线程池(thread poll)
       + 主线程负责接收请求, 分发给其他线程处理

   + **运行时的库**

     + 作用: 提供性能和可靠性
     + **问题一** : 如何找到远程服务器, DNS域名解析;
     + 传输协议: UDP传输RPC软件包

   + Sun的RPC使用的存根编译器

     ```
     rpcgen
     ```

4. 许多系统处理的问题是: 字节序?

   + 大端存储: 从最高有效位到最低有效位的存储;
   + 小端存储

### Sun的网络文件系统NFS

1. 分布式文件系统:

   + 服务器将数据存在其磁盘上, 客户端通过良好的协议消息请求数据;

   {% asset_img sunNFS.jpg %}

2. **问题一:** Sun的网络文件系统的核心?

   + 核心: **服务器的故障**要能简单快速的恢复;
   + 服务器故障的原因?
     + 外在(硬件的断电) || 内在(内存的泄漏)	|| 通信(网络异常)
   + **幂等性**处理服务器的故障: Client请求重试
     + 幂等性: 执行多次和一次访问的效果是一样的;

3. NFS设计的关键: 文件句柄(FILE handle)

   + 采用协议: 无状态协议, 服务器不会跟踪每个客户端的行为;
   + **文件句柄**: server 能够正确访问文件
     + 卷标识符: 通知服务器, 指向哪个文件系统;
     + inode号: 告诉服务器, 请求分区中的哪个文件;
     + 时代号: 服务器确保 **新 / 旧**文件句柄

4. **问题二: **提高client 和server之间访问的性能?

   + 方法: 客户端缓存;

5. **问题三:** client缓存造成的缓存一致性问题?

   + 客户端: 
     + 关闭时刷新
     + 添加属性缓存, 每次检查
   + 服务器
     + 对服务器的写入, 在返回成功之前, 必须强制写入稳定存储(备用电源);

### Andrew 文件系统AFS

1. AFS设计的理念?
   + 为了让服务器和客户端交互最少, 采用**全文缓存** 和 **引入回调**的方式, 支持更多client访问
2. **全文缓存**
   + 客户端第一次进行访问时: 将相关内容进行全文缓存, 后续的read and write 相当于在本地进行;
3. **引入回调**
   + 解决问题: 目录层次结构的访问花费很多时间.
   + 作用: 当用户第一次访问server时, 每一层的访问存入本地时, 服务器会设置一个**remzi**回调, 后面服务器通知客户端文件是否改变; 减少client每次的询问;
4. 问题: 缓存一致性问题的解决?
   + 方法: 更新可见性 和 缓存陈旧

## 虚拟监视器(virtual machine monitor)

1. 虚拟监视器
   + 作用: 位于一个或多个操作系统 和 硬件之间, 并为每个运行的OS提供**控制机器**的假象;(实际上是VMM控制硬件)
   + OS 提供的虚拟化CPU和内存: 让每个用户认为单独享有CPU和内存, 以及进程间切换时, 共享内存;
2. VMM 和 OS 抽象的区别?
   + OS抽象: 提供新的抽象和漂亮的接口;
   + VMM 抽象: 抽象与硬件相同;